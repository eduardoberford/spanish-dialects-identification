{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "QA_bert_ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVr8sce42-Du"
      },
      "source": [
        "### Import necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgWxpel8317G",
        "outputId": "0ede85b2-6c9e-44b4-9cd1-550a35a34343"
      },
      "source": [
        "!pip install transformers seqeval[gpu]\n",
        "!pip install datasets\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.20.1)\n",
            "Requirement already satisfied: seqeval[gpu] in /usr/local/lib/python3.7/dist-packages (1.2.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2022.6.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.8.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.11.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.64.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.21.6)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.1.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.8.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.25.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval[gpu]) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (3.1.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval[gpu]) (1.4.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.7/dist-packages (2.3.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.7/dist-packages (from datasets) (3.0.0)\n",
            "Requirement already satisfied: dill<0.3.6 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.3.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from datasets) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.7/dist-packages (from datasets) (0.70.13)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (2022.5.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from datasets) (4.11.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.7/dist-packages (from datasets) (4.64.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from datasets) (1.21.6)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from datasets) (3.8.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.1.0 in /usr/local/lib/python3.7/dist-packages (from datasets) (0.8.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (4.1.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (6.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from huggingface-hub<1.0.0,>=0.1.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (2022.6.15)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->datasets) (1.25.11)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.7.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.3.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->datasets) (3.8.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2022.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbHoJEJd46mA"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from collections import Counter\n",
        "from datasets import load_dataset\n",
        "from transformers import XLNetTokenizer, XLNetForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import EarlyStoppingCallback\n",
        "from sklearn.metrics import f1_score, accuracy_score, precision_score, recall_score\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8NsCc923Oy6"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\")\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls '/content/drive/MyDrive/eth_CS4NLP/project/qadata'\n",
        "train_path = '/content/drive/MyDrive/eth_CS4NLP/project/qadata/final_train.csv'\n",
        "dev_path = '/content/drive/MyDrive/eth_CS4NLP/project/qadata/final_dev.csv'\n",
        "test_path = '/content/drive/MyDrive/eth_CS4NLP/project/qadata/vardial_test.txt'"
      ],
      "metadata": {
        "id": "NYAgkgF8kHQf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c204c46b-4ad0-403b-b2d3-526a5f23d84a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "final_dev.csv\t final_train.gsheet  vardial_dev.txt   vardial_train_1.csv\n",
            "final_train.csv  pred_bert_output    vardial_test.txt  vardial_train_2.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dial_label = {\n",
        "    0 : 'EML',\n",
        "    1 : 'NAP',\n",
        "    2 : 'PMS',\n",
        "    3 : 'FUR',\n",
        "    4 : 'LLD',\n",
        "    5 : 'LIJ',\n",
        "    6 : 'LMO',\n",
        "    7 : 'ROA_TARA',\n",
        "    8 : 'SCN', \n",
        "    9 : 'VEC',\n",
        "    10 : 'SC'\n",
        "}\n",
        "\n",
        "fold_label = {\n",
        "    'EML' : 0,\n",
        "    'NAP' : 1,\n",
        "    'PMS' : 2,\n",
        "    'FUR' : 3,\n",
        "    'LLD' : 4,\n",
        "    'LIJ' : 5,\n",
        "    'LMO' : 6,\n",
        "    'ROA_TARA' : 7,\n",
        "    'SCN' : 8,\n",
        "    'VEC' : 9,\n",
        "    'SC' : 10\n",
        "}\n",
        "\n",
        "def explain_label(label : int) -> str:\n",
        "    \"\"\" \n",
        "    Given an integer label, convert it to the corresponding string label\n",
        "    :param int label: integer label to be converted\n",
        "    :return: string corresponding to the given label\n",
        "    \"\"\"\n",
        "    return dial_label[label]\n",
        "\n",
        "def encode_label(label : str) -> int:\n",
        "    \"\"\" \n",
        "    Given a string label, encode it to the corresponding index\n",
        "    :param string label: string label to be converted\n",
        "    :return: int corresponding to the given label\n",
        "    \"\"\"\n",
        "    return fold_label[label]"
      ],
      "metadata": {
        "id": "uz78UizYkNQ3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_dev = pd.read_csv(dev_path)#, sep = \"\\t\", names=[\"text\", \"label\"])\n",
        "#df_dev['label'] = df_dev['label'].apply(encode_label)\n",
        "#df_dev = df_dev.fillna('')\n",
        "#-\n",
        "df_train = pd.read_csv(train_path)#, sep = \"\\t\", names=[\"text\", \"label\"])\n",
        "#df_train_=df_train[['text','label']]\n",
        "#df_train_.drop_duplicates(subset ='text',keep = False, inplace = True, ignore_index=True) \n",
        "#SUBSET\n",
        "#f_train_ = df_train_.iloc[0:1000,:] \n",
        "df_test = pd.read_csv(test_path, sep = \"\\t\", names=[\"text\"])\n",
        "df_test['label']=0 #add label column to the testset and assign 0 to all row\n",
        "df_test.shape"
      ],
      "metadata": {
        "id": "fcMhfJERkPw0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39e70c52-eaed-4baa-dc4f-bf87b515a423"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11087, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 78
        },
        "id": "C1wUiNsYpeoi",
        "outputId": "9e8dec27-973f-4095-a35b-c40a9d2b5bde"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                           text  label\n",
              "0  El record de parteçipasion el xe del Bresa .      9"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c4a399d2-ce57-466c-8366-43145fbae30a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>El record de parteçipasion el xe del Bresa .</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c4a399d2-ce57-466c-8366-43145fbae30a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c4a399d2-ce57-466c-8366-43145fbae30a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c4a399d2-ce57-466c-8366-43145fbae30a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrCVTe59fxoN",
        "outputId": "bd3fc180-89b5-438a-9095-28e23737b915"
      },
      "source": [
        "# Create dictionaries to transform from labels to id and vice-versa.\n",
        "id2label = {0 : 'EML',\n",
        "    1 : 'NAP',\n",
        "    2 : 'PMS',\n",
        "    3 : 'FUR',\n",
        "    4 : 'LLD',\n",
        "    5 : 'LIJ',\n",
        "    6 : 'LMO',\n",
        "    7 : 'ROA_TARA',\n",
        "    8 : 'SCN', \n",
        "    9 : 'VEC',\n",
        "    10 : 'SC'}\n",
        "label2id = {v:k for k,v in id2label.items()}\n",
        "num_labels = len(id2label)\n",
        "print(id2label)"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{0: 'EML', 1: 'NAP', 2: 'PMS', 3: 'FUR', 4: 'LLD', 5: 'LIJ', 6: 'LMO', 7: 'ROA_TARA', 8: 'SCN', 9: 'VEC', 10: 'SC'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import Dataset\n",
        "train_ds = Dataset.from_pandas(df_train)\n",
        "dev_ds = Dataset.from_pandas(df_dev)\n",
        "test_ds = Dataset.from_pandas(df_test)\n",
        "# Example of instance of the dataset\n",
        "train_ds[18]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuzS8EgrqfuN",
        "outputId": "2f290e1a-ba96-44e7-89c5-488e9c08a81f"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 2,\n",
              " 'text': \"Damentre ch'a lo fasìa, a l'ha sentù 'n sìfol daré 'd chiel:\"}"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Tokenizing data - Model name"
      ],
      "metadata": {
        "id": "VgIxc5qiQGvq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**model_name**\n",
        "- [x] m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0\n",
        "- [x] 'dbmdz/bert-base-italian-cased'\n",
        "- [x] 'dbmdz/bert-base-italian-xxl-cased'\n",
        "- [x] 'dbmdz/bert-base-italian-uncased'\n",
        "- [x] mrm8488/bert-italian-finedtuned-squadv1-it-alfa"
      ],
      "metadata": {
        "id": "PfozgTU_LEfa"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-rin6nkAAQs"
      },
      "source": [
        "\n",
        "# Load BERT tokenizer.\n",
        "model_name = 'dbmdz/bert-base-italian-xxl-cased'\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_5hGacF6Iqm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3a0ca71-531e-4a14-db3f-014a066a3202"
      },
      "source": [
        "#tokenizer = XLNetTokenizer.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading configuration file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a6f63287bf77965c2a075e2eb7b021b66b863c245cb1ac8cd51d73c9b9711f11.d4216e94150242f24c22ebc3ff97fb4079388b3e36c7e029e29e0f833f5db329\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"dbmdz/bert-base-italian-xxl-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32102\n",
            "}\n",
            "\n",
            "loading file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/846441ee4ed51de6c6076976e9436700b2aacf08efbaff5fb1cb3a2ac52b16bf.83ca512ab51c5bc2809e83002a054b84ab85a200b98d5c0eb036d7611ee4362e\n",
            "loading file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/tokenizer.json from cache at None\n",
            "loading file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/added_tokens.json from cache at None\n",
            "loading file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/special_tokens_map.json from cache at None\n",
            "loading file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/tokenizer_config.json from cache at /root/.cache/huggingface/transformers/b54c8394ba5912e6f52245553e5b0b2681466c0fd7ff1f2e37bb0830d652aca4.6391beef2ceed2cdba47401eb12680200856c97d2f2b56143e515d7c0f36a66a\n",
            "loading configuration file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a6f63287bf77965c2a075e2eb7b021b66b863c245cb1ac8cd51d73c9b9711f11.d4216e94150242f24c22ebc3ff97fb4079388b3e36c7e029e29e0f833f5db329\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"dbmdz/bert-base-italian-xxl-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32102\n",
            "}\n",
            "\n",
            "loading configuration file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a6f63287bf77965c2a075e2eb7b021b66b863c245cb1ac8cd51d73c9b9711f11.d4216e94150242f24c22ebc3ff97fb4079388b3e36c7e029e29e0f833f5db329\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"dbmdz/bert-base-italian-xxl-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32102\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WSl2snPOhsTz"
      },
      "source": [
        "\n",
        "def encode_dataset(dataset: datasets.arrow_dataset.Dataset) -> list:\n",
        "  '''\n",
        "  Transforming each instance of the dataset with the Tokenizer\n",
        "  '''\n",
        "  encoded_dataset = []\n",
        "  for item in dataset:\n",
        "    # Tokenize the sentence.\n",
        "    sentence_encoded = tokenizer(item['text'],\n",
        "                                return_tensors=\"pt\", \n",
        "                                padding='max_length', \n",
        "                                truncation=True, \n",
        "                                max_length=50)\n",
        "    \n",
        "    sentence_encoded['labels'] = torch.LongTensor(np.array([item['label']]))\n",
        "    encoded_dataset.append(sentence_encoded)\n",
        "\n",
        "  # Reduce dimensionality of tensors.\n",
        "  for item in encoded_dataset:\n",
        "    for key in item:\n",
        "      item[key] = torch.squeeze(item[key])\n",
        "  return encoded_dataset"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoJQmMbvH1TH"
      },
      "source": [
        "# Tokenizing datasets\n",
        "encoded_dataset_train = encode_dataset(train_ds)\n",
        "encoded_dataset_dev = encode_dataset(dev_ds)\n",
        "encoded_dataset_test = encode_dataset(test_ds)\n"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7kip0P3Dqb3x",
        "outputId": "3875d85a-e738-43de-bf2b-23aa349a4b1a"
      },
      "source": [
        "# Example of dataset\n",
        "for token, token_label in zip(tokenizer.convert_ids_to_tokens(encoded_dataset_train[50][\"input_ids\"]), encoded_dataset_train[50][\"input_ids\"]):\n",
        "  print('{0:10}  {1}'.format(token, token_label))"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]       102\n",
            "In          369\n",
            "tu          241\n",
            "1999        5285\n",
            "u           349\n",
            "l           181\n",
            "'           1553\n",
            "è           198\n",
            "s           109\n",
            "##tà        232\n",
            "##u         30887\n",
            "istitu      1639\n",
            "##ì         30946\n",
            "##u         30887\n",
            "u           349\n",
            "Nu          9531\n",
            "##cle       2867\n",
            "##o         30879\n",
            "Opera       9434\n",
            "##tivo      705\n",
            "per         156\n",
            "l           181\n",
            "'           1553\n",
            "Archeo      26104\n",
            "##logia     1783\n",
            "Sub         13804\n",
            "##acque     28740\n",
            "##a         30878\n",
            "pru         7693\n",
            "##g         30891\n",
            "##è         30915\n",
            "##ttu       794\n",
            "da          203\n",
            "So          756\n",
            "##pri       787\n",
            "##nte       1696\n",
            "##nd        21433\n",
            "##enza      351\n",
            "per         156\n",
            "i           134\n",
            "Beni        12194\n",
            "Archeo      26104\n",
            "##logici    6412\n",
            "della       213\n",
            "Liguria     21764\n",
            ",           1307\n",
            "che         158\n",
            "a           111\n",
            "l           181\n",
            "[SEP]       103\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykLCWLBX6elf"
      },
      "source": [
        "# Fine tunning of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "k99EV8x3J-uz",
        "outputId": "21014bf4-0f87-46ee-9af7-c699e55d44cc"
      },
      "source": [
        "# Common training arguments\n",
        "training_args = TrainingArguments(\n",
        "    num_train_epochs=2,\n",
        "    per_device_train_batch_size=128,\n",
        "    per_device_eval_batch_size=128,\n",
        "    logging_dir='logs',\n",
        "    no_cuda=False,  \n",
        "    output_dir = 'drive/MyDrive/eth_CS4NLP/project',\n",
        ")\n",
        "\n",
        "# Dictionary to save the results\n",
        "models_performance ={}\n",
        "\n",
        "# FINE TUNING PROCESS\n",
        "\n",
        "# create model\n",
        "#model = XLNetForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels)\n",
        "\n",
        "'''model.transformer.mask_emb.requires_grad = False\n",
        "model.transformer.word_embedding.weight.requires_grad = False\n",
        "for name, param in model.transformer.layer.named_parameters():\n",
        "  try:\n",
        "    layer = int(name[:2])\n",
        "  except ValueError:\n",
        "    try:\n",
        "      layer = int(name[:1])\n",
        "    except ValueError:\n",
        "      layer = 0\n",
        "  if layer <= 20:\n",
        "    param.requires_grad = False'''\n",
        "\n",
        "\n",
        "# Create trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    tokenizer=tokenizer,\n",
        "    args=training_args,\n",
        "    train_dataset=encoded_dataset_train,)\n",
        "\n",
        "# Fine tunning\n",
        "trainer.train()\n"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n",
            "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
            "loading configuration file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/a6f63287bf77965c2a075e2eb7b021b66b863c245cb1ac8cd51d73c9b9711f11.d4216e94150242f24c22ebc3ff97fb4079388b3e36c7e029e29e0f833f5db329\n",
            "Model config BertConfig {\n",
            "  \"_name_or_path\": \"dbmdz/bert-base-italian-xxl-cased\",\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"id2label\": {\n",
            "    \"0\": \"LABEL_0\",\n",
            "    \"1\": \"LABEL_1\",\n",
            "    \"2\": \"LABEL_2\",\n",
            "    \"3\": \"LABEL_3\",\n",
            "    \"4\": \"LABEL_4\",\n",
            "    \"5\": \"LABEL_5\",\n",
            "    \"6\": \"LABEL_6\",\n",
            "    \"7\": \"LABEL_7\",\n",
            "    \"8\": \"LABEL_8\",\n",
            "    \"9\": \"LABEL_9\",\n",
            "    \"10\": \"LABEL_10\"\n",
            "  },\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"label2id\": {\n",
            "    \"LABEL_0\": 0,\n",
            "    \"LABEL_1\": 1,\n",
            "    \"LABEL_10\": 10,\n",
            "    \"LABEL_2\": 2,\n",
            "    \"LABEL_3\": 3,\n",
            "    \"LABEL_4\": 4,\n",
            "    \"LABEL_5\": 5,\n",
            "    \"LABEL_6\": 6,\n",
            "    \"LABEL_7\": 7,\n",
            "    \"LABEL_8\": 8,\n",
            "    \"LABEL_9\": 9\n",
            "  },\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.20.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 32102\n",
            "}\n",
            "\n",
            "loading weights file https://huggingface.co/dbmdz/bert-base-italian-xxl-cased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/ce00a92f9057500be8f5bf9f847998bae83b3fc702899cb0738f418a26e1f751.4df6732e65b1159caa33c155d3c5d4dc44c0957ee2ea68f597d4b03c7c1853ea\n",
            "Some weights of the model checkpoint at dbmdz/bert-base-italian-xxl-cased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at dbmdz/bert-base-italian-xxl-cased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 316279\n",
            "  Num Epochs = 2\n",
            "  Instantaneous batch size per device = 128\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 4942\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='4942' max='4942' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [4942/4942 1:21:41, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>500</td>\n",
              "      <td>0.297500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1000</td>\n",
              "      <td>0.120400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1500</td>\n",
              "      <td>0.101300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2000</td>\n",
              "      <td>0.085600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2500</td>\n",
              "      <td>0.075700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3000</td>\n",
              "      <td>0.049900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3500</td>\n",
              "      <td>0.049000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4000</td>\n",
              "      <td>0.045800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4500</td>\n",
              "      <td>0.042700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to drive/MyDrive/eth_CS4NLP/project/checkpoint-500\n",
            "Configuration saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-500/config.json\n",
            "Model weights saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-500/special_tokens_map.json\n",
            "Saving model checkpoint to drive/MyDrive/eth_CS4NLP/project/checkpoint-1000\n",
            "Configuration saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-1000/config.json\n",
            "Model weights saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-1000/special_tokens_map.json\n",
            "Saving model checkpoint to drive/MyDrive/eth_CS4NLP/project/checkpoint-1500\n",
            "Configuration saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-1500/config.json\n",
            "Model weights saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-1500/special_tokens_map.json\n",
            "Saving model checkpoint to drive/MyDrive/eth_CS4NLP/project/checkpoint-2000\n",
            "Configuration saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-2000/config.json\n",
            "Model weights saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-2000/special_tokens_map.json\n",
            "Saving model checkpoint to drive/MyDrive/eth_CS4NLP/project/checkpoint-2500\n",
            "Configuration saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-2500/config.json\n",
            "Model weights saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-2500/special_tokens_map.json\n",
            "Saving model checkpoint to drive/MyDrive/eth_CS4NLP/project/checkpoint-3000\n",
            "Configuration saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-3000/config.json\n",
            "Model weights saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-3000/special_tokens_map.json\n",
            "Saving model checkpoint to drive/MyDrive/eth_CS4NLP/project/checkpoint-3500\n",
            "Configuration saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-3500/config.json\n",
            "Model weights saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-3500/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-3500/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-3500/special_tokens_map.json\n",
            "Saving model checkpoint to drive/MyDrive/eth_CS4NLP/project/checkpoint-4000\n",
            "Configuration saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-4000/config.json\n",
            "Model weights saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-4000/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-4000/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-4000/special_tokens_map.json\n",
            "Saving model checkpoint to drive/MyDrive/eth_CS4NLP/project/checkpoint-4500\n",
            "Configuration saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-4500/config.json\n",
            "Model weights saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-4500/pytorch_model.bin\n",
            "tokenizer config file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-4500/tokenizer_config.json\n",
            "Special tokens file saved in drive/MyDrive/eth_CS4NLP/project/checkpoint-4500/special_tokens_map.json\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=4942, training_loss=0.09112088509485916, metrics={'train_runtime': 4903.0665, 'train_samples_per_second': 129.013, 'train_steps_per_second': 1.008, 'total_flos': 1.62545363251374e+16, 'train_loss': 0.09112088509485916, 'epoch': 2.0})"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWjv2M1eOf6E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "3e2f2c96-cec0-4572-ab56-e810cbb47566"
      },
      "source": [
        "# Get the predicted labels\n",
        "preds = trainer.predict(encoded_dataset_dev)\n",
        "predictions = preds.predictions.argmax(-1)\n",
        "\n",
        "# Create array with predicted labels and expected.\n",
        "true_values = np.array(preds.label_ids).flatten()\n",
        "predicted_values = np.array(preds.predictions.argmax(-1)).flatten()\n",
        "\n",
        "# Filter the labels. We only produce a label for each word. We filter labels\n",
        "# of subwords and special tokens, such as PAD\n",
        "proc_predicted_values = [prediction for prediction, label in zip(predicted_values, true_values) if label != -100]\n",
        "proc_true_values = [label for prediction, label in zip(predicted_values, true_values) if label != -100]\n",
        "\n",
        "# Evaluate models\n",
        "model_performance = {}\n",
        "model_performance['accuracy'] = accuracy_score(proc_true_values, proc_predicted_values)\n",
        "model_performance['precision_micro'] = precision_score(proc_true_values, proc_predicted_values, average='micro')\n",
        "model_performance['precision_macro'] = precision_score(proc_true_values, proc_predicted_values, average='macro')\n",
        "model_performance['recall_micro'] = recall_score(proc_true_values, proc_predicted_values, average='micro')\n",
        "model_performance['recall_macro'] = recall_score(proc_true_values, proc_predicted_values, average='macro')\n",
        "model_performance['f1_micro'] = f1_score(proc_true_values, proc_predicted_values, average='micro')\n",
        "model_performance['f1_macro'] = f1_score(proc_true_values, proc_predicted_values, average='macro')\n",
        "\n",
        "model_performance['confusion_matrix'] = confusion_matrix(proc_true_values, proc_predicted_values)\n",
        "model_performance['confusion_matrix_normalized'] = confusion_matrix(proc_true_values, proc_predicted_values, normalize='true')"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 79070\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='618' max='618' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [618/618 03:35]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIO4C4BI2AyB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "23016d7b-ed57-4995-c84e-0f14cbbeb27d"
      },
      "source": [
        "model_performance"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.983407107626154,\n",
              " 'confusion_matrix': array([[ 1397,     2,     4,     4,     5,     6,    35,     1,     1,\n",
              "             7,     2],\n",
              "        [    0,  4293,    10,     1,     2,     5,    18,    25,    46,\n",
              "            20,     7],\n",
              "        [    9,     4, 11865,     0,     5,     9,    71,     1,    16,\n",
              "            25,    11],\n",
              "        [    7,     2,     4,  2838,     5,     5,    29,     2,     7,\n",
              "             4,     3],\n",
              "        [    4,     2,    12,     1,  4635,     0,    35,     0,     0,\n",
              "             9,     6],\n",
              "        [    3,     9,     9,     3,     0,  3785,    33,     6,    17,\n",
              "            42,     5],\n",
              "        [   36,     6,    37,     6,    16,    32, 17001,     3,    29,\n",
              "            78,    22],\n",
              "        [    0,    10,     2,     4,     1,     1,     3,  2520,     9,\n",
              "            14,     2],\n",
              "        [    1,    11,    12,     1,     2,     3,    31,    16, 11860,\n",
              "            22,    16],\n",
              "        [    1,     3,    13,     7,     6,    14,   103,    11,    20,\n",
              "         10830,    12],\n",
              "        [    0,     0,    11,     1,     4,     3,    16,     0,    34,\n",
              "            11,  6734]]),\n",
              " 'confusion_matrix_normalized': array([[9.54234973e-01, 1.36612022e-03, 2.73224044e-03, 2.73224044e-03,\n",
              "         3.41530055e-03, 4.09836066e-03, 2.39071038e-02, 6.83060109e-04,\n",
              "         6.83060109e-04, 4.78142077e-03, 1.36612022e-03],\n",
              "        [0.00000000e+00, 9.69731195e-01, 2.25886605e-03, 2.25886605e-04,\n",
              "         4.51773210e-04, 1.12943302e-03, 4.06595889e-03, 5.64716512e-03,\n",
              "         1.03907838e-02, 4.51773210e-03, 1.58120623e-03],\n",
              "        [7.49001332e-04, 3.32889481e-04, 9.87433422e-01, 0.00000000e+00,\n",
              "         4.16111851e-04, 7.49001332e-04, 5.90878828e-03, 8.32223702e-05,\n",
              "         1.33155792e-03, 2.08055925e-03, 9.15446072e-04],\n",
              "        [2.40880936e-03, 6.88231246e-04, 1.37646249e-03, 9.76600138e-01,\n",
              "         1.72057811e-03, 1.72057811e-03, 9.97935306e-03, 6.88231246e-04,\n",
              "         2.40880936e-03, 1.37646249e-03, 1.03234687e-03],\n",
              "        [8.50340136e-04, 4.25170068e-04, 2.55102041e-03, 2.12585034e-04,\n",
              "         9.85331633e-01, 0.00000000e+00, 7.44047619e-03, 0.00000000e+00,\n",
              "         0.00000000e+00, 1.91326531e-03, 1.27551020e-03],\n",
              "        [7.66871166e-04, 2.30061350e-03, 2.30061350e-03, 7.66871166e-04,\n",
              "         0.00000000e+00, 9.67535787e-01, 8.43558282e-03, 1.53374233e-03,\n",
              "         4.34560327e-03, 1.07361963e-02, 1.27811861e-03],\n",
              "        [2.08502259e-03, 3.47503765e-04, 2.14293988e-03, 3.47503765e-04,\n",
              "         9.26676706e-04, 1.85335341e-03, 9.84651917e-01, 1.73751882e-04,\n",
              "         1.67960153e-03, 4.51754894e-03, 1.27418047e-03],\n",
              "        [0.00000000e+00, 3.89711613e-03, 7.79423227e-04, 1.55884645e-03,\n",
              "         3.89711613e-04, 3.89711613e-04, 1.16913484e-03, 9.82073266e-01,\n",
              "         3.50740452e-03, 5.45596259e-03, 7.79423227e-04],\n",
              "        [8.35073069e-05, 9.18580376e-04, 1.00208768e-03, 8.35073069e-05,\n",
              "         1.67014614e-04, 2.50521921e-04, 2.58872651e-03, 1.33611691e-03,\n",
              "         9.90396660e-01, 1.83716075e-03, 1.33611691e-03],\n",
              "        [9.07441016e-05, 2.72232305e-04, 1.17967332e-03, 6.35208711e-04,\n",
              "         5.44464610e-04, 1.27041742e-03, 9.34664247e-03, 9.98185118e-04,\n",
              "         1.81488203e-03, 9.82758621e-01, 1.08892922e-03],\n",
              "        [0.00000000e+00, 0.00000000e+00, 1.61432345e-03, 1.46756677e-04,\n",
              "         5.87026710e-04, 4.40270032e-04, 2.34810684e-03, 0.00000000e+00,\n",
              "         4.98972703e-03, 1.61432345e-03, 9.88259466e-01]]),\n",
              " 'f1_macro': 0.9805004385512308,\n",
              " 'f1_micro': 0.983407107626154,\n",
              " 'precision_macro': 0.982040962941178,\n",
              " 'precision_micro': 0.983407107626154,\n",
              " 'recall_macro': 0.9790006433082545,\n",
              " 'recall_micro': 0.983407107626154}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sF73PIb58Ddh"
      },
      "source": [
        "# Models evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YUb4rYtp8Kuf"
      },
      "source": [
        "F1-micro and F1-macro for each model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsBFUoukwl-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cb4b2c7-1cdc-434b-ad62-7cb49e2f663e"
      },
      "source": [
        "print('------------Model performance------------')\n",
        "print(f'  accuracy: {model_performance[\"accuracy\"]}')\n",
        "print(f'  f1-micro: {model_performance[\"f1_micro\"]}')\n",
        "print(f'  f1-macro: {model_performance[\"f1_macro\"]}')\n",
        "print(f'  precision_macro: {model_performance[\"precision_macro\"]}')\n",
        "print(f'  precision_micro: {model_performance[\"precision_micro\"]}')\n",
        "print(f'  recall_macro: {model_performance[\"recall_macro\"]}')\n",
        "print(f'  recall_micro: {model_performance[\"recall_micro\"]}')\n",
        "print()"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------Model performance------------\n",
            "  accuracy: 0.983407107626154\n",
            "  f1-micro: 0.983407107626154\n",
            "  f1-macro: 0.9805004385512308\n",
            "  precision_macro: 0.982040962941178\n",
            "  precision_micro: 0.983407107626154\n",
            "  recall_macro: 0.9790006433082545\n",
            "  recall_micro: 0.983407107626154\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_df = pd.DataFrame({'pred_label':predicted_values})\n",
        "pred_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        },
        "id": "uHBnvWQM8Vwd",
        "outputId": "ce18bcf4-552f-4f1a-8283-e3f0e41e2c6f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       pred_label\n",
              "0               5\n",
              "1               9\n",
              "2               6\n",
              "3               6\n",
              "4               9\n",
              "...           ...\n",
              "79065          10\n",
              "79066           6\n",
              "79067           3\n",
              "79068           1\n",
              "79069           9\n",
              "\n",
              "[79070 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d60ddc8-5b44-493e-9067-f8c1ae882748\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>pred_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79065</th>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79066</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79067</th>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79068</th>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79069</th>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>79070 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d60ddc8-5b44-493e-9067-f8c1ae882748')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d60ddc8-5b44-493e-9067-f8c1ae882748 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d60ddc8-5b44-493e-9067-f8c1ae882748');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "pred_df.to_csv('new_pred_dbmdz_bert-base-italian-xxl-cased.csv',index=False)\n",
        "files.download('new_pred_dbmdz_bert-base-italian-xxl-cased.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "NohOghez9V-0",
        "outputId": "b716c28e-4a85-4b93-ea39-abbeb45d45bd"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_3dc10c10-5336-4876-a290-e4521c305e9d\", \"new_pred_dbmdz_bert-base-italian-xxl-cased.csv\", 164971)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Prediction"
      ],
      "metadata": {
        "id": "GZebNXYFgcRv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the predicted labels\n",
        "preds = trainer.predict(encoded_dataset_test)\n",
        "predictions = preds.predictions.argmax(-1)\n",
        "\n",
        "# Create array with predicted labels and expected.\n",
        "true_values = np.array(preds.label_ids).flatten()\n",
        "predicted_values = np.array(preds.predictions.argmax(-1)).flatten()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "xsnjV-nfgezh",
        "outputId": "3c0081ee-4998-4077-e3e9-309553dca3e8"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Prediction *****\n",
            "  Num examples = 11087\n",
            "  Batch size = 128\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='705' max='618' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [618/618 54:47]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test = pd.DataFrame({'pred_label':predicted_values})\n",
        "from google.colab import files\n",
        "pred_test.to_csv('new_test_pred_dbmdz_bert-base-italian-xxl-cased.csv',index=False)\n",
        "files.download('new_test_pred_dbmdz_bert-base-italian-xxl-cased.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 32
        },
        "id": "Xw8OLH5IkBjp",
        "outputId": "e5638ca2-2d47-4d8c-826b-9e40d3c08669"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_d0b5d30f-4ec7-44ef-bc3d-b55e52afc06e\", \"new_test_pred_dbmdz_bert-base-italian-xxl-cased.csv\", 22323)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pred_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTR9xVehk7T7",
        "outputId": "df4da69e-54b7-4472-86bf-c98669291375"
      },
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(11087, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "MJTIM_ytk8j7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}