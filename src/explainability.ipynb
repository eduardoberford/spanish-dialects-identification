{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainability of LR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import explain_label\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "data_train = pd.read_csv(\"train.csv\")\n",
    "data, labels = data_train['text'].values, data_train['label'].values.astype(int)\n",
    "_, data, _, labels = train_test_split(data, labels, test_size=0.1, random_state=1)\n",
    "X_train, X_dev, y_train, y_dev = train_test_split(data, labels, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9998019681321025, nan, None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from models import LogisticRegressionITDI\n",
    "\n",
    "model = LogisticRegressionITDI()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01634345, 0.01442741, 0.01566705, 0.93947412, 0.01408797])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict_proba(\"de buena cosa de l'Alto Aragón\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_dev)\n",
    "X_dev = model.vectorizer.transform(X_dev)\n",
    "X_dev = model.scaler.transform(X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28134, 151300)\n",
      "(28134,)\n",
      "(28134,)\n"
     ]
    }
   ],
   "source": [
    "print(X_dev.shape)\n",
    "print(y_dev.shape)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\eduar\\Documents\\CS 4650\\Final Project\\spanish-dialects-identification\\src\\explainability.ipynb Cell 6\u001b[0m line \u001b[0;36m4\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eduar/Documents/CS%204650/Final%20Project/spanish-dialects-identification/src/explainability.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m vocab \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mvectorizer\u001b[39m.\u001b[39mget_feature_names_out()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eduar/Documents/CS%204650/Final%20Project/spanish-dialects-identification/src/explainability.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m most \u001b[39m=\u001b[39m []\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/eduar/Documents/CS%204650/Final%20Project/spanish-dialects-identification/src/explainability.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (sample, X, true, pred) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(\u001b[39mzip\u001b[39m(data[\u001b[39m'\u001b[39;49m\u001b[39mtext\u001b[39;49m\u001b[39m'\u001b[39;49m], X_dev, y_dev, y_pred)):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eduar/Documents/CS%204650/Final%20Project/spanish-dialects-identification/src/explainability.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mif\u001b[39;00m true \u001b[39m!=\u001b[39m pred:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eduar/Documents/CS%204650/Final%20Project/spanish-dialects-identification/src/explainability.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eduar/Documents/CS%204650/Final%20Project/spanish-dialects-identification/src/explainability.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m         \u001b[39m# print(f\"## Sample {i} ##\")\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/eduar/Documents/CS%204650/Final%20Project/spanish-dialects-identification/src/explainability.ipynb#W5sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m         \u001b[39m# print(sample)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eduar/Documents/CS%204650/Final%20Project/spanish-dialects-identification/src/explainability.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m#vec_feat = np.exp([X_dev[i, feat]*model.coef_[9][feat] for feat in X.indices]) - 1\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/eduar/Documents/CS%204650/Final%20Project/spanish-dialects-identification/src/explainability.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         wrong_feat \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mexp([X_dev[i, feat]\u001b[39m*\u001b[39mmodel\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mcoef_[pred][feat] \u001b[39mfor\u001b[39;00m feat \u001b[39min\u001b[39;00m X\u001b[39m.\u001b[39mindices]) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "\u001b[1;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "vocab = model.vectorizer.get_feature_names_out()\n",
    "most = []\n",
    "for i, (sample, X, true, pred) in enumerate(zip(data['text'], X_dev, y_dev, y_pred)):\n",
    "    \n",
    "    if true != pred:\n",
    "\n",
    "        # print(f\"## Sample {i} ##\")\n",
    "        # print(sample)\n",
    "        #vec_feat = np.exp([X_dev[i, feat]*model.coef_[9][feat] for feat in X.indices]) - 1\n",
    "        wrong_feat = np.exp([X_dev[i, feat]*model.model.coef_[pred][feat] for feat in X.indices]) - 1\n",
    "        \n",
    "        for idx, feat in enumerate(wrong_feat):\n",
    "            if feat > 0.2 or feat < -0.2:\n",
    "                most.append((i, vocab[X.indices[idx]], explain_label(pred), explain_label(true), feat))\n",
    "\n",
    "        # print(ind)\n",
    "        # print([vocab[feat] for feat in X.indices])\n",
    "        # print(\"VEC\", vec_feat)\n",
    "        # print(\"LMO\", lmo_feat, \"\\n\")\n",
    "\n",
    "pd.set_option('display.max_columns', None)  # or 1000\n",
    "pd.set_option('display.max_rows', None)  # or 1000\n",
    "pd.set_option('display.max_colwidth', None)  # or 199\n",
    "expl_df = pd.DataFrame(most, columns=['sample', 'word', 'pred', 'true', 'dev']).groupby(['word', 'pred', 'true']).agg(['unique'])\n",
    "\n",
    "\n",
    "expl_df['sample', 'unique'] = expl_df['sample', 'unique'].apply(lambda x: x if len(x)>2 else np.nan)\n",
    "expl_df.dropna(inplace=True)\n",
    "expl_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sample = []\n",
    "\n",
    "for x in expl_df['sample']['unique']:\n",
    "    sample.extend(x)\n",
    "\n",
    "np.unique(sample).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/31 [00:00<?, ?it/s]/var/folders/93/zm8s9_vj1q58xfmd38jbfglc0000gn/T/ipykernel_18291/2159768547.py:41: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c_val = c_val  / np.sum(c_val)\n",
      "100%|██████████| 31/31 [00:30<00:00,  1.01it/s]\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "i=0\n",
    "colors = sns.color_palette('rocket_r')[0:11]\n",
    "words = ['atride', 'che', 'chi', \"chissu\", \"chisti\", \"con\", \"cossa\", \"di\", \"digo\", \"dui\", \"el\", \"erani\", \"fattu\", \"ghe\", \"li\", \"lu\", \"me\", \"no\", \"non\", \"per\", \"perchè\", \"quel\", \"saru\", \"se\", \"si\", \"spariss\", \"sì\", \"ve\", \"vegnir\", \"vo\", \"vogio\"]\n",
    "conf = ['PMS_VEC', 'LMO_VEC', 'SC_SCN', 'SCN_SC', 'SCN_SC', 'PMS_LMO', 'LMO_VEC', 'SCN_SC', 'LMO_VEC', 'SCN_SC', 'VEC_LMO', 'SCN_SC', 'SCN_SC', 'VEC_LMO', 'SCN_SC', 'SCN_SC', 'LMO_VEC', 'VEC_SCN', 'SC_LMOVEC', 'LMO_VEC', 'LMO_VEC', 'LMO_VEC', 'SC_SCN', 'VEC_LMO', 'SCN_SC', 'PMS_LMO', 'PMS_VEC', 'LMO_VEC', 'LMO_VEC', 'NAP_SCN', 'LMO_VEC']\n",
    "for w, conf in tqdm(zip(words, conf), total=len(words)):\n",
    "\n",
    "    train = []\n",
    "    data_train = pd.read_csv(\"data/train.csv\", ) \n",
    "    data_train['text'] = data_train['text'].apply(lambda x: x if w in x else np.nan)\n",
    "    data_train.dropna(inplace=True)\n",
    "    for label, num in zip(np.unique(data_train['label'].values, return_counts=True)[0], np.unique(data_train['label'].values, return_counts=True)[1]):\n",
    "        train.extend([explain_label(label)]*num)\n",
    "\n",
    "    val = [] \n",
    "    data_v = data.copy()\n",
    "    data_v['text'] = data_v['text'].apply(lambda x: x if w in x else np.nan)\n",
    "    data_v.dropna(inplace=True)\n",
    "    for label, num in zip(np.unique(data_v['label'].values, return_counts=True)[0], np.unique(data_v['label'].values, return_counts=True)[1]):\n",
    "        val.extend([label]*num)\n",
    "\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(9, 6)\n",
    "    \n",
    "    labels_t, counts_t = np.unique(np.array(train), return_counts=True)\n",
    "    labels, counts = np.unique(np.array(val), return_counts=True)\n",
    "    c_train, c_val = [0]*11, [0]*11\n",
    "    i1 = i2 = 0\n",
    "    for j, l in enumerate(['EML', 'FUR', 'LIJ', 'LLD', 'LMO', 'NAP', 'PMS', 'RT', 'SC','SCN', 'VEC']):\n",
    "        if i1 < len(labels_t) and l == labels_t[i1]: \n",
    "            c_train[j] = counts_t[i1]\n",
    "            i1 += 1\n",
    "    for j, l in enumerate(['EML', 'FUR', 'LIJ', 'LLD', 'LMO', 'NAP', 'PMS', 'RT', 'SC','SCN', 'VEC']):\n",
    "        if i2 < len(labels) and  l == labels[i2]: \n",
    "            c_val[j] = counts[i2]\n",
    "            i2 += 1\n",
    "\n",
    "    c_train = c_train  / np.sum(c_train)\n",
    "    c_val = c_val  / np.sum(c_val)\n",
    "\n",
    "    # plt.bar(range(11), height=c_train, align='center', width=0.3, color=colors[0], label=\"Training distribution\")\n",
    "    # plt.bar(np.array(range(11))+0.3, height=c_val, align='center', width=0.3, color=colors[3], label = \"Validation distribution\")\n",
    "\n",
    "    #plt.plot(c_train)\n",
    "    from scipy.interpolate import interp1d\n",
    "    xnew = np.linspace(0, 10, num=300, endpoint=True)\n",
    "    f_cubic = interp1d(range(0,11), c_train, kind='nearest')\n",
    "    f_cubic2 = interp1d(range(0,11), c_val, kind='nearest')\n",
    "    plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "    plt.plot(xnew, f_cubic(xnew), label=\"training\")\n",
    "    plt.fill_between(xnew, f_cubic(xnew), color='#539ecd',alpha=0.2)\n",
    "\n",
    "    plt.plot(xnew, f_cubic2(xnew), label=\"validation\")\n",
    "    plt.fill_between(xnew, f_cubic2(xnew), color='#FFA54C',alpha=0.2)\n",
    "\n",
    "    plt.xticks(np.array(range(0,11)), ['EML', 'FUR', 'LIJ', 'LLD', 'LMO', 'NAP', 'PMS', 'RT', 'SC','SCN', 'VEC'])\n",
    "\n",
    "\n",
    "    plt.ylim(bottom=0, top=1.1)\n",
    "    plt.xlim(left=0, right=10)\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.savefig(f\"plots/confounding/{w}_{conf}.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('cs4nlp')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0263a1dfeb8862614b07bcce79ebe8d40befa6db1ea41957ac0a9f2757809afa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
